# ğŸ“Š Cell Segmentation using YOLOv8

## ğŸ“ **Project Description**

This project performs **cell segmentation** using the **YOLOv8** model. It identifies and segments cells from microscopy images, producing labeled outputs with bounding boxes and masks. The project includes training, inference, and evaluation functionalities with configurable parameters.

---

![cellseg](https://github.com/user-attachments/assets/8d0e8169-0088-4ef8-b493-2f5f11f2aea9)


## ğŸš€ **Features**

- **Training:** Uses YOLOv8 for training the model on cell images.
- **Inference:** Segments cells and outputs labeled images.
- **Metrics:** Includes evaluation metrics for model performance.
- **Visualization:** Displays and saves segmentation results.

---

## ğŸ”¥ **Project Structure**

```
Cell_Segmentation-main/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/                  # Training images
â”‚   â”œâ”€â”€ test/                   # Testing images
â”‚   â””â”€â”€ labels/                 # Labels for segmentation
â”œâ”€â”€ models/                     # YOLOv8 pre-trained models
â”œâ”€â”€ outputs/                    # Output results of segmentation
â”œâ”€â”€ utils/                      # Helper scripts
â”‚   â”œâ”€â”€ dataset_utils.py        # Dataset handling functions
â”‚   â”œâ”€â”€ visualization.py        # Visualization helpers
â”‚   â””â”€â”€ metrics.py              # Evaluation metrics
â”œâ”€â”€ app.py                      # Main application script
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ config.yaml                 # YOLO model configuration
â””â”€â”€ main.py                     # Training and inference script
```

---

## âš™ï¸ **Installation and Setup**

### **1. Clone the repository:**

```bash
git clone <repository_link>
cd Cell_Segmentation-main
```

### **2. Create a virtual environment (optional but recommended):**

```bash
python -m venv venv
source venv/bin/activate  # For Linux
venv\Scripts\activate     # For Windows
```

### **3. Install dependencies:**

```bash
pip install -r requirements.txt
```

---

## ğŸ› ï¸ **Usage**

### **1. Train the Model:**

```bash
python main.py --mode train --config config.yaml
```

### **2. Perform Inference:**

```bash
python main.py --mode inference --config config.yaml
```

### **3. Run the Application:**

```bash
python app.py
```

---

## ğŸ§ª **Configuration**

The project uses a `config.yaml` file to manage the model settings. You can modify the following parameters:

```yaml
model: 'yolov8n-seg.pt'          # YOLOv8 model
image_size: 640                   # Input image size
batch_size: 16                    # Batch size
epochs: 50                        # Number of training epochs
```

---

## ğŸ“Š **Evaluation Metrics**

The project calculates the following metrics:

- **mAP** (Mean Average Precision)
- **IoU** (Intersection over Union)
- **Recall & Precision**

---

## ğŸ–¼ï¸ **Visualization**

Segmented images are saved in the `outputs/` folder. You can visualize the results by running:

```bash
python utils/visualization.py
```

---

## ğŸ› ï¸ **Troubleshooting**

- Ensure all dependencies in `requirements.txt` are installed.
- Adjust the `config.yaml` parameters if performance is low.
- Check the `outputs/` folder for results after inference.

---

## ğŸ“š **References**

- [YOLOv8 Documentation](https://docs.ultralytics.com/)
- [OpenCV](https://opencv.org/)
- [Python](https://www.python.org/)

---

## ğŸ‘©â€ğŸ’» **Contributing**

Feel free to contribute to this project by submitting pull requests or reporting issues.

---

## âš–ï¸ **License**

This project is licensed under the MIT License. See the `LICENSE` file for details.

---

## ğŸ“¬ **Contact**

For any inquiries or issues, please contact: **Viplove Thakran**

